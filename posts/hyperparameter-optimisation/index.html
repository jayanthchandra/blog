<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=dark data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>Hyperparameter Tuning is just a Resource Scheduling Problem &#183; JC</title>
<meta name=title content="Hyperparameter Tuning is just a Resource Scheduling Problem &#183; JC"><meta name=keywords content="ML,"><link rel=canonical href=https://jchandra.com/posts/hyperparameter-optimisation/><link type=text/css rel=stylesheet href=/css/main.bundle.min.6835005deb03361a63daa0f215c157c04a02d4105393c699a083c9b5b4646983ea9e8226a58d603f65328e01ff0ba67c42716cbb5e5d322feafa09718538bd00.css integrity="sha512-aDUAXesDNhpj2qDyFcFXwEoC1BBTk8aZoIPJtbRkaYPqnoImpY1gP2UyjgH/C6Z8QnFsu15dMi/q+glxhTi9AA=="><script type=text/javascript src=/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.b6411b5d4cd56c0068d34c4acbce043846adad56b824e3d486a06d3459aed2eb7f7413874b7871cc2c822c8c8834cbed944022918bcc8cca710a962167c36d32.js integrity="sha512-tkEbXUzVbABo00xKy84EOEatrVa4JOPUhqBtNFmu0ut/dBOHS3hxzCyCLIyINMvtlEAikYvMjMpxCpYhZ8NtMg==" data-copy=Copy data-copied=Copied></script><script src=/lib/zoom/zoom.min.f592a181a15d2a5b042daa7f746c3721acf9063f8b6acd175d989129865a37d400ae0e85b640f9ad42cd98d1f8ad30931718cf8811abdcc5fcb264400d1a2b0c.js integrity="sha512-9ZKhgaFdKlsELap/dGw3Iaz5Bj+Las0XXZiRKYZaN9QArg6FtkD5rULNmNH4rTCTFxjPiBGr3MX8smRADRorDA=="></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://jchandra.com/posts/hyperparameter-optimisation/"><meta property="og:site_name" content="JC"><meta property="og:title" content="Hyperparameter Tuning is just a Resource Scheduling Problem"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-05-02T00:34:08+05:30"><meta property="article:modified_time" content="2025-05-02T00:34:08+05:30"><meta property="article:tag" content="ML"><meta name=twitter:card content="summary"><meta name=twitter:title content="Hyperparameter Tuning is just a Resource Scheduling Problem"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"","name":"Hyperparameter Tuning is just a Resource Scheduling Problem","headline":"Hyperparameter Tuning is just a Resource Scheduling Problem","inLanguage":"en","url":"https:\/\/jchandra.com\/posts\/hyperparameter-optimisation\/","author":{"@type":"Person","name":"JC"},"copyrightYear":"2025","dateCreated":"2025-05-02T00:34:08\u002b05:30","datePublished":"2025-05-02T00:34:08\u002b05:30","dateModified":"2025-05-02T00:34:08\u002b05:30","keywords":["ML"],"mainEntityOfPage":"true","wordCount":"1484"}]</script><meta name=author content="JC"><link href=https://www.linkedin.com/in/jayanthchandra/ rel=me><script src=/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><link type=text/css rel=stylesheet href=/lib/katex/katex.min.7e7e35e3ef02b7b437449a44ca3fac62ec1ed39cb8312b680a00fe8ac60badc95b063b694636b8440856f7f5e8c2cc9e6b0efb581179b2656c7e1e97558c7096.css integrity="sha512-fn414+8Ct7Q3RJpEyj+sYuwe05y4MStoCgD+isYLrclbBjtpRja4RAhW9/Xowsyeaw77WBF5smVsfh6XVYxwlg=="><script defer src=/lib/katex/katex.min.cadd45c1af1f44bdaf196dc9b104f1daeb29043f0dc59155ffe22847510a04390a0b7a859400d420a626204f7fc5ddb07c19311de1c66b25e19c2559d3e126a8.js integrity="sha512-yt1Fwa8fRL2vGW3JsQTx2uspBD8NxZFV/+IoR1EKBDkKC3qFlADUIKYmIE9/xd2wfBkxHeHGayXhnCVZ0+EmqA=="></script><script defer src=/lib/katex/auto-render.min.e9b2833d28623d18c071d78ef13e9c79d695122d296af3dbcee7bf1bf6518b0565bab59939267fbc8f5faf696193c20f5caef3e7501969cfb306f6738032730d.js integrity="sha512-6bKDPShiPRjAcdeO8T6cedaVEi0pavPbzue/G/ZRiwVlurWZOSZ/vI9fr2lhk8IPXK7z51AZac+zBvZzgDJzDQ==" onload=renderMathInElement(document.body)></script><meta name=theme-color></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start gap-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ class="text-base font-medium text-gray-500 hover:text-gray-900">JC</a></nav><nav class="hidden md:flex items-center gap-x-5 md:ml-12 h-12"><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Blog</p></a><a href=https://github.com/jayanthchandra/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><span class=mr-1><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span><p class="text-base font-medium" title>GitHub</p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center gap-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400 ltr:mr-1 rtl:ml-1"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Blog</p></a></li><li class=mt-1><a href=https://github.com/jayanthchandra/ target=_blank class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><div class=mr-2><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div><p class="text-bg font-bg" title>GitHub</p></a></li></ul></div></label></div></div><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header id=single_header class="mt-5 max-w-prose"><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Hyperparameter Tuning is just a Resource Scheduling Problem</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2025-05-02T00:34:08+05:30>2 May 2025</time><span class="px-2 text-primary-500">&#183;</span><span>1484 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">7 mins</span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt=JC src=/img/user_hu_aa73e8455543a7f9.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">JC</div><div class="text-sm text-neutral-700 dark:text-neutral-400">Staff Engineer</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://www.linkedin.com/in/jayanthchandra/ target=_blank aria-label=Linkedin rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-10"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#what-is-hpo->What is HPO ?</a><ul><li><a href=#objective-function>Objective Function</a><ul><li><a href=#example>Example</a></li></ul></li></ul></li><li><a href=#hpo-as-a-scheduling-problem>HPO as a Scheduling Problem</a></li><li><a href=#advanced-algorithms-scheduling-hpo>Advanced Algorithms: Scheduling HPO</a><ul><li><a href=#asha>ASHA</a></li><li><a href=#hyperband>Hyperband</a></li><li><a href=#population-based-training-pbt>Population-Based Training (PBT)</a></li><li><a href=#comparison>Comparison</a></li></ul></li><li><a href=#future-trends>Future Trends</a></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#what-is-hpo->What is HPO ?</a><ul><li><a href=#objective-function>Objective Function</a><ul><li><a href=#example>Example</a></li></ul></li></ul></li><li><a href=#hpo-as-a-scheduling-problem>HPO as a Scheduling Problem</a></li><li><a href=#advanced-algorithms-scheduling-hpo>Advanced Algorithms: Scheduling HPO</a><ul><li><a href=#asha>ASHA</a></li><li><a href=#hyperband>Hyperband</a></li><li><a href=#population-based-training-pbt>Population-Based Training (PBT)</a></li><li><a href=#comparison>Comparison</a></li></ul></li><li><a href=#future-trends>Future Trends</a></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})(),function(){var t,e=$("#TableOfContents");if(e.length>0){t=$(window);function n(){var s,o=t.scrollTop(),i=$(".anchor"),n="";if(i.each(function(e,t){t=$(t),t.offset().top-$(window).height()/3<=o&&(n=decodeURIComponent(t.attr("id")))}),s=e.find("a.active"),s.length==1&&s.eq(0).attr("href")=="#"+n)return!0;s.each(function(e,t){$(t).removeClass("active")}),e.find('a[href="#'+n+'"]').addClass("active"),e.find('a[href="#'+n+'"]').parentsUntil("#TableOfContents").each(function(e,t){$(t).children("a").parents("ul").show()})}t.on("scroll",n),$(document).ready(function(){n()})}}()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><p>When you hear <em>hyperparameter tuning</em>, you might think of trying lots of different model settings to find the best one—maybe using grid search, random search, or some fancy algorithm. But when you&rsquo;re doing this at scale, especially with limited time or compute, it&rsquo;s not just about finding the best settings. It&rsquo;s about how you manage your resources. You have a bunch of models to try, but you can’t run them all fully.</p><p>So, the real problem becomes: given your limited computer power, which sets of settings should you even bother trying? For the ones you start, which ones should you stop early if they don&rsquo;t look promising? And which ones seem good enough that you should give them more time and resources to see how well they can really do?</p><p>That&rsquo;s exactly what some advanced tuning methods like ASHA, Hyperband, and Population-Based Training do constantly. They are making decisions about starting, stopping, and giving more power to different trials.</p><p>When you look at hyperparameter tuning this way, it stops feeling so much like a clever searching puzzle. Instead, it feels a lot like managing a list of tasks waiting to be done, where you have a limited budget of time and computer power. You have to decide which task to work on next, which ones to cut short if they&rsquo;re not going well, and how to share your resources. That&rsquo;s basically what a good scheduler does!</p><h2 class="relative group">What is HPO ?<div id=what-is-hpo- class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#what-is-hpo- aria-label=Anchor>#</a></span></h2><p>Hyperparameter optimization (HPO) is the process of choosing the best values for hyperparameters in a machine learning model. Hyperparameters are the settings or configurations that you decide before training the model. Examples include:</p><ul><li>Learning rate: How fast the model learns from data.</li><li>Batch size: The number of training samples used to update the model&rsquo;s weights at each iteration.</li><li>Number of layers in a neural network</li></ul><p>The space of possible hyperparameters is often vast, and the relationship between hyperparameters and model performance is typically non-linear and noisy. This means small changes in hyperparameters can lead to large fluctuations in performance.</p><h3 class="relative group">Objective Function<div id=objective-function class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#objective-function aria-label=Anchor>#</a></span></h3><p>The goal of HPO is to identify the set of hyperparameters that maximize (or minimize) some performance measure, usually the validation accuracy or loss of a model after training. This is typically expressed as an objective function.</p><p>$$\text{maximize} \ f(\theta) = \text{Accuracy}, \quad \text{or minimize} \ f(\theta) = \text{Loss}$$</p><p>The challenge lies in the fact that evaluating \(f(\theta)\) is often computationally expensive. It requires training a model with the specific hyperparameters \(\theta\) and then evaluating its performance on a validation set. This process can take hours or even days, especially when working with large datasets or complex models.</p><h4 class="relative group">Example<div id=example class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#example aria-label=Anchor>#</a></span></h4><p>Grid search is the most straightforward method. You define a grid of hyperparameter values, and the algorithm tries every possible combination.
Let’s say you want to tune two hyperparameters: learning rate and batch size. You define the grid like this:</p><ul><li>Learning rates: 0.001, 0.01, 0.1</li><li>Batch sizes: 32, 64, 128</li></ul><p>The grid search will try all combinations:</p><ul><li>(0.001, 32)</li><li>(0.001, 64)</li><li>(0.001, 128)</li><li>(0.01, 32)</li><li>(0.01, 64) &mldr;&mldr;&mldr;..</li></ul><p>This approach is called exhaustive search because you are testing every possible combination, ensuring you explore all options. But here’s the catch: Grid Search is computationally expensive. If the model takes a long time to train (say hours), and you have more hyperparameters or larger ranges, the time to complete all combinations can quickly become impractical.</p><p>This is where resource scheduling comes into play, especially in large-scale tasks, where you need to decide how to allocate limited computational resources efficiently.</p><h2 class="relative group">HPO as a Scheduling Problem<div id=hpo-as-a-scheduling-problem class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#hpo-as-a-scheduling-problem aria-label=Anchor>#</a></span></h2><p>At a high level, hyperparameter optimization is about managing limited resources (like compute or time) and making decisions on which models to train, when to stop training them, and when to allocate more resources to the best-performing configurations.</p><p>Key scheduling-like aspects of HPO:</p><ul><li><p>Limited Resources (Compute Budget):</p><p>Just like in scheduling problems, HPO algorithms are constrained by available resources. The more resources we can allocate, the more hyperparameter configurations we can test.</p></li><li><p>Evaluation Time (Task Duration):</p><p>Training a model with specific hyperparameters is time-consuming, like a long-running job in a job queue. Scheduling decisions are made on whether to keep running a long task or preempt it if other tasks seem more promising.</p></li><li><p>Exploration vs Exploitation (Job Allocation):</p><p>Exploration: Trying new or random configurations, akin to scheduling a new, untried job.</p><p>Exploitation: Allocating more resources to well-performing models, much like prioritizing jobs that are nearing completion and performing well.</p></li><li><p>Preemption & Job Promotion:</p><p>Early stopping (preemption) of low-performing models is equivalent to canceling jobs that aren’t worth the resources. Promotion happens when a model performs well in early trials and gets more resources, similar to scheduling more CPU time for the jobs that are performing best.</p></li></ul><h2 class="relative group">Advanced Algorithms: Scheduling HPO<div id=advanced-algorithms-scheduling-hpo class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#advanced-algorithms-scheduling-hpo aria-label=Anchor>#</a></span></h2><p>These algorithms make the most efficient use of limited resources, helping us find the best hyperparameters faster. Let&rsquo;s break them down.</p><h3 class="relative group">ASHA<div id=asha class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#asha aria-label=Anchor>#</a></span></h3><p>ASHA (Asynchronous Successive Halving Algorithm) is a highly efficient method for optimizing hyperparameters that focuses on allocating resources in a way that eliminates poor-performing models early, allowing us to concentrate computational power on the promising ones. It&rsquo;s an enhancement of the traditional Successive Halving (SH) method, but with the added benefit of asynchrony, meaning we can evaluate multiple configurations in parallel, speeding up the process.<figure><img class="my-0 rounded-md" loading=lazy src=/images/b3_asha.png alt=ASHA></figure></p><ol><li><p><strong>Initial Allocation</strong>: Each model starts with a small amount of resources, \( r_0 \).</p><p>$$
r_0 = \text{Initial Resources (e.g., 1 epoch)}
$$</p></li><li><p><strong>Subsequent Allocation</strong>: After each stage, allocate more resources to the remaining models.</p><p>$$
r_s = r_0 \times \eta^s
$$</p><p>Where \( \eta \) is the scaling factor (typically 2 or 3), and \( s \) is the stage number.</p></li><li><p><strong>Remaining Models</strong>: At each stage, the number of models is reduced by a factor of \( \eta \), i.e., only the top-performing \( \frac{1}{\eta} \) fraction of models are retained.
$$
N * s = \frac{N*{s-1}}{\eta}
$$</p></li></ol><h3 class="relative group">Hyperband<div id=hyperband class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#hyperband aria-label=Anchor>#</a></span></h3><p>Hyperband is an enhancement of Successive Halving (SH) that allocates resources to different configurations in parallel, speeding up hyperparameter optimization (HPO).In the early stages, it explores the hyperparameter space with smaller resource budgets (Exploration), Later, it reallocates more resources to the best-performing models (Exploitation)</p><ol><li><p><strong>Parallel Successive Halving</strong>:
Hyperband runs multiple SH processes in parallel with different initial resource budgets, exploring various configurations at different levels of commitment.</p></li><li><p><strong>Resource Allocation</strong>:
The resource for each stage \( s \) is calculated as:</p><p>$$
r_s = r_0 \times \eta^s
$$</p><p>Where:</p><ul><li>\( r_0 \) is the initial resource,</li><li>\( \eta \) is the reduction factor (e.g., 2 or 3),</li><li>\( s \) is the current stage.</li></ul></li><li><p><strong>Resource Scaling</strong>:
Resources grow exponentially at each stage. For example, if \( r_0 = 1 \) and \( \eta = 2 \):</p><ul><li>At \( s = 1 \): \( r_1 = 1 \times 2^1 = 2 \)</li><li>At \( s = 2 \): \( r_2 = 1 \times 2^2 = 4 \)</li><li>At \( s = 3 \): \( r_3 = 1 \times 2^3 = 8 \)</li></ul></li><li><p><strong>Trials Reduction</strong>:
At each stage, the number of trials \( N*s \) decreases exponentially:</p><p>$$
N_s = \frac{N*{s-1}}{\eta}
$$</p></li><li><p><strong>Total Computational Budget</strong>:
The total budget \( B \) is split across stages, where:
$$
B = \sum_{s=0}^{S} r_s \times N_s
$$
This ensures that more resources are allocated to the better-performing models as the process progresses.</p></li></ol><h3 class="relative group">Population-Based Training (PBT)<div id=population-based-training-pbt class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#population-based-training-pbt aria-label=Anchor>#</a></span></h3><p>PBT is a more advanced method where multiple models (the &ldquo;population&rdquo;) are trained in parallel, and their hyperparameters are evolved over time. The idea is to explore hyperparameters and exploit good ones by periodically &ldquo;mutating&rdquo; hyperparameters of the best models and copying them to weaker models.<figure><img class="my-0 rounded-md" loading=lazy src=/images/b3_pbt.png alt=PBT></figure></p><p>Typical Flow of PBT:</p><ol><li><p><strong>Initialization</strong>: The models are initialized with a set of random hyperparameters \( \theta_0 \).</p><p>$$
\theta_0 = \text{Random Initialization of Hyperparameters}
$$</p></li><li><p><strong>Evaluation and Selection</strong>: After training, models are ranked based on performance (e.g., validation loss). The best-performing models are selected:</p><p>$$
\text{Top Models} = { \theta^* }
$$</p></li><li><p><strong>Mutation</strong>: Hyperparameters of the top models are <strong>perturbed</strong> to create new configurations.
$$
\theta_{\text{new}} = \theta^* + \Delta \theta
$$
Where \( \Delta \theta \) is a random perturbation.</p></li></ol><h3 class="relative group">Comparison<div id=comparison class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#comparison aria-label=Anchor>#</a></span></h3><table><thead><tr><th><strong>HPO Concept</strong></th><th><strong>ASHA</strong></th><th><strong>Hyperband</strong></th><th><strong>PBT</strong></th></tr></thead><tbody><tr><td><strong>Resource Allocation</strong></td><td>Allocates more resources to better-performing models</td><td>Similar to ASHA but with more exploration</td><td>Mutates best models, reallocates resources</td></tr><tr><td><strong>Early Stopping</strong></td><td>Eliminates poorly performing models early</td><td>Similar to ASHA</td><td>Evaluates and evolves the population of models</td></tr><tr><td><strong>Exploration vs Exploitation</strong></td><td>Explores a wide range, then exploits top models</td><td>Balances exploration and exploitation</td><td>Exploits best-performing models, mutates others</td></tr><tr><td><strong>Scheduling Analogy</strong></td><td>Job preemption, task prioritization</td><td>Job parallelism, dynamic scheduling</td><td>Task migration, job evolution</td></tr></tbody></table><h2 class="relative group">Future Trends<div id=future-trends class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#future-trends aria-label=Anchor>#</a></span></h2><ul><li><strong>Meta-Learning:</strong> Meta-learning optimizes hyperparameters by learning from past optimization experiences, typically via optimization of a meta-objective function.</li><li><strong>Evolutionary Algorithms</strong>: Evolutionary algorithms like genetic algorithms are used for more adaptive search strategies. They simulate natural selection processes to iteratively evolve better-performing solutions</li></ul><hr><p>[1] <a href=https://www.researchgate.net/publication/348497481_AutoML_for_Multi-Label_Classification_Overview_and_Empirical_Evaluation target=_blank>Research Gate Article</a></p><p>[2] <a href=https://docs.ray.io/en/latest/tune/api/schedulers.html target=_blank>Ray Scheduler</a></p></div></div><script>var oid="views_posts/hyperparameter-optimisation.md",oid_likes="likes_posts/hyperparameter-optimisation.md"</script><script type=text/javascript src=/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/posts/python-pickle/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">The Dark Side of Python’s pickle – How to Backdoor an AI Model</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2025-03-13T00:34:08+05:30>13 March 2025</time>
</span></span></a></span><span></span></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400"><ul class="flex flex-col list-none sm:flex-row"><li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href=/tags/ title=Tags>Tags</a></li></ul></nav><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
JC</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://jchandra.com/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>